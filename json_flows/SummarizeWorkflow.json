{"id":"6d878f9e-498b-49b2-abca-65860f4ea16d","data":{"nodes":[{"id":"Prompt-FCttw","type":"genericNode","position":{"x":107.13851897026086,"y":6.511321374011288},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"Help me to summarize the next YouTube video very carefully and taking into consideration the main topic and a second topic having the next data from the video:\n\n{title&description}\n\nTRANSCRIPT:\n\n{transcript}","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt"},"title&description":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"title&description","display_name":"title&description","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"transcript":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"transcript","display_name":"transcript","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["title&description","transcript"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-FCttw","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":515,"positionAbsolute":{"x":107.13851897026086,"y":6.511321374011288},"dragging":false},{"id":"YouTubeTranscriptComponent-64xOe","type":"genericNode","position":{"x":-980.735141014631,"y":468.3463484528458},"data":{"type":"YouTubeTranscriptComponent","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, BoolInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nfrom youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\r\nimport re\r\n\r\nclass YouTubeTranscriptComponent(Component):\r\n    display_name = \"YouTube Transcript Fetcher\"\r\n    description = \"Fetches transcripts from YouTube videos with optional timestamps.\"\r\n    icon = \"youtube\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"youtube_id\",\r\n            display_name=\"YouTube Video ID\",\r\n            info=\"The ID of the YouTube video.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"include_timestamps\",\r\n            display_name=\"Include Timestamps\",\r\n            info=\"Boolean to include timestamps in the transcript.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Transcript\", name=\"transcript\", method=\"fetch_transcript\"),\r\n    ]\r\n\r\n    preferred_languages = [\r\n        'en', 'es', 'fr', 'de', 'pt', 'ru', 'zh', 'nl', 'ja', 'ko', 'hi', 'tr', \r\n        'pl', 'sv', 'no', 'da', 'fi', 'el', 'th', 'vi'\r\n    ]\r\n\r\n    def fetch_transcript(self) -> Data:\r\n        youtube_id = self.youtube_id\r\n        include_timestamps = self.include_timestamps\r\n\r\n        # Validate YouTube ID\r\n        if not youtube_id:\r\n            self.status = \"YouTube ID is empty.\"\r\n            return Data(data={\"error\": \"YouTube ID is empty.\"})\r\n\r\n        try:\r\n            # Fetch the transcript in the first available preferred language\r\n            transcript = self.get_transcript_in_preferred_language(youtube_id)\r\n\r\n            if transcript is None:\r\n                self.status = \"No transcript found in preferred languages.\"\r\n                return Data(data={\"error\": \"No transcript found in preferred languages.\"})\r\n\r\n            # Process the transcript\r\n            processed_transcript = self.process_transcript(transcript, include_timestamps)\r\n\r\n            self.status = \"Transcript fetched successfully.\"\r\n            return Data(data={\"transcript\": processed_transcript})\r\n\r\n        except VideoUnavailable:\r\n            self.status = \"Video is unavailable.\"\r\n            return Data(data={\"error\": \"Video is unavailable.\"})\r\n        except TranscriptsDisabled:\r\n            self.status = \"Transcripts are disabled for this video.\"\r\n            return Data(data={\"error\": \"Transcripts are disabled for this video.\"})\r\n        except NoTranscriptFound:\r\n            self.status = \"No transcript found for this video.\"\r\n            return Data(data={\"error\": \"No transcript found for this video.\"})\r\n        except Exception as e:\r\n            self.status = f\"An error occurred: {str(e)}\"\r\n            return Data(data={\"error\": f\"An error occurred: {str(e)}\"})\r\n\r\n    def get_transcript_in_preferred_language(self, video_id: str):\r\n        try:\r\n            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n            for lang in self.preferred_languages:\r\n                if transcript_list.find_transcript([lang]):\r\n                    return transcript_list.find_transcript([lang]).fetch()\r\n        except Exception as e:\r\n            self.status = f\"An error occurred while fetching the transcript: {str(e)}\"\r\n            return None\r\n        return None\r\n\r\n    def process_transcript(self, transcript: list, include_timestamps: bool) -> str:\r\n        if include_timestamps:\r\n            return \"\\n\".join([f\"{self.format_timestamp(entry['start'])} - {entry['text']}\" for entry in transcript])\r\n        else:\r\n            return \"\\n\".join([entry['text'] for entry in transcript])\r\n\r\n    def format_timestamp(self, start: float) -> str:\r\n        hours, remainder = divmod(start, 3600)\r\n        minutes, seconds = divmod(remainder, 60)\r\n        if hours > 0:\r\n            return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\r\n        else:\r\n            return f\"{int(minutes):02}:{int(seconds):02}\"\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"include_timestamps":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"include_timestamps","display_name":"Include Timestamps","advanced":false,"dynamic":false,"info":"Boolean to include timestamps in the transcript.","title_case":false,"type":"bool","load_from_db":false},"youtube_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"youtube_id","display_name":"YouTube Video ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The ID of the YouTube video.","title_case":false,"type":"str"}},"description":"Fetches transcripts from YouTube videos with optional timestamps.","icon":"youtube","base_classes":["Data"],"display_name":"String YT Transcript","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"transcript","display_name":"Transcript","method":"fetch_transcript","value":"__UNDEFINED__","cache":true}],"field_order":["youtube_id","include_timestamps"],"beta":false,"edited":true,"official":false},"id":"YouTubeTranscriptComponent-64xOe"},"selected":false,"width":384,"height":412,"positionAbsolute":{"x":-980.735141014631,"y":468.3463484528458},"dragging":false},{"id":"YouTubeVideoInfoExtractor-hGwEv","type":"genericNode","position":{"x":-971.6183247594001,"y":-67.89049767979634},"data":{"type":"YouTubeVideoInfoExtractor","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"api_key","display_name":"YouTube API Key","advanced":false,"input_types":[],"dynamic":false,"info":"Your YouTube Data API key.","title_case":false,"password":true,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, SecretStrInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nimport requests\r\n\r\nclass YouTubeVideoInfoExtractor(Component):\r\n    display_name = \"YouTube Video Info Extractor\"\r\n    description = \"Extracts the title and description of a YouTube video using its ID.\"\r\n    icon = \"youtube\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"youtube_id\",\r\n            display_name=\"YouTube Video ID\",\r\n            info=\"The ID of the YouTube video.\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"YouTube API Key\",\r\n            info=\"Your YouTube Data API key.\",\r\n            advanced=False,\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Video Info\", name=\"video_info\", method=\"fetch_video_info\"),\r\n    ]\r\n\r\n    def fetch_video_info(self) -> Data:\r\n        youtube_id = self.youtube_id.strip()\r\n        api_key = self.api_key.strip()  # Use strip directly since SecretStrInput stores the value as string\r\n\r\n        if not youtube_id:\r\n            return Data(data={\"error\": \"YouTube ID cannot be empty\"})\r\n        \r\n        if not api_key:\r\n            return Data(data={\"error\": \"API Key cannot be empty\"})\r\n\r\n        try:\r\n            api_url = f\"https://www.googleapis.com/youtube/v3/videos?id={youtube_id}&part=snippet&key={api_key}\"\r\n            response = requests.get(api_url)\r\n            response.raise_for_status()\r\n\r\n            video_data = response.json()\r\n            if not video_data[\"items\"]:\r\n                return Data(data={\"error\": \"Invalid YouTube ID or video not found\"})\r\n\r\n            snippet = video_data[\"items\"][0][\"snippet\"]\r\n            title = snippet.get(\"title\", \"No Title\")\r\n            description = snippet.get(\"description\", \"\")\r\n\r\n            return Data(data={\"title\": title, \"description\": description})\r\n\r\n        except requests.exceptions.RequestException as e:\r\n            return Data(data={\"error\": str(e)})\r\n        except KeyError as e:\r\n            return Data(data={\"error\": f\"Key error: {str(e)}\"})\r\n        except Exception as e:\r\n            return Data(data={\"error\": f\"An unexpected error occurred: {str(e)}\"})","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"youtube_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"youtube_id","display_name":"YouTube Video ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The ID of the YouTube video.","title_case":false,"type":"str"}},"description":"Extracts the title and description of a YouTube video using its ID.","icon":"youtube","base_classes":["Data"],"display_name":"Title & Description JSON","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"video_info","display_name":"Video Info","method":"fetch_video_info","value":"__UNDEFINED__","cache":true}],"field_order":["youtube_id","api_key"],"beta":false,"edited":false,"official":false},"id":"YouTubeVideoInfoExtractor-hGwEv"},"selected":false,"width":384,"height":430,"positionAbsolute":{"x":-971.6183247594001,"y":-67.89049767979634},"dragging":false},{"id":"ParseData-PwO5q","type":"genericNode","position":{"x":-432.2824949252321,"y":-58.26093695033935},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"TITLE:\n{title}\n\nDESCRIPTION:\n{description}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-PwO5q"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":-432.2824949252321,"y":-58.26093695033935},"dragging":true},{"id":"ParseData-D1HB6","type":"genericNode","position":{"x":-421.1597344854331,"y":435.20902690797317},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{transcript}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-D1HB6"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":-421.1597344854331,"y":435.20902690797317},"dragging":false},{"id":"TextInput-E8gVT","type":"genericNode","position":{"x":-1738.341581544959,"y":109.86854952021415},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"2ymwP6_Fu0U","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextInput-E8gVT"},"selected":true,"width":384,"height":308,"positionAbsolute":{"x":-1738.341581544959,"y":109.86854952021415},"dragging":false},{"id":"TextOutput-wPTnN","type":"genericNode","position":{"x":1130.350264076778,"y":379.8324305609746},"data":{"type":"TextOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as output.","title_case":false,"type":"str"}},"description":"Display a text output in the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextOutput-wPTnN"},"selected":false,"width":384,"height":308},{"id":"OpenAIModel-RqeC4","type":"genericNode","position":{"x":633.7798630332566,"y":126.99988791531842},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"json_mode","display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"1024","name":"max_tokens","display_name":"Max Tokens","advanced":false,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"required":false,"placeholder":"","show":true,"value":"gpt-4-turbo-preview","name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"https://litellm-3xlzyox7uq-uc.a.run.app/","name":"openai_api_base","display_name":"OpenAI API Base","advanced":false,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str"},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"output_schema","display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1,"name":"seed","display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","openai_api_key","temperature","stream","system_message","seed"],"beta":false,"edited":false},"id":"OpenAIModel-RqeC4"},"selected":false,"width":384,"height":792,"positionAbsolute":{"x":633.7798630332566,"y":126.99988791531842},"dragging":false}],"edges":[{"source":"ParseData-PwO5q","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-PwO5qœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-FCttw","targetHandle":"{œfieldNameœ:œtitle&descriptionœ,œidœ:œPrompt-FCttwœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"title&description","id":"Prompt-FCttw","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-PwO5q","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-PwO5q{œdataTypeœ:œParseDataœ,œidœ:œParseData-PwO5qœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-FCttw{œfieldNameœ:œtitle&descriptionœ,œidœ:œPrompt-FCttwœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"YouTubeVideoInfoExtractor-hGwEv","sourceHandle":"{œdataTypeœ:œYouTubeVideoInfoExtractorœ,œidœ:œYouTubeVideoInfoExtractor-hGwEvœ,œnameœ:œvideo_infoœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-PwO5q","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-PwO5qœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-PwO5q","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"YouTubeVideoInfoExtractor","id":"YouTubeVideoInfoExtractor-hGwEv","name":"video_info","output_types":["Data"]}},"id":"reactflow__edge-YouTubeVideoInfoExtractor-hGwEv{œdataTypeœ:œYouTubeVideoInfoExtractorœ,œidœ:œYouTubeVideoInfoExtractor-hGwEvœ,œnameœ:œvideo_infoœ,œoutput_typesœ:[œDataœ]}-ParseData-PwO5q{œfieldNameœ:œdataœ,œidœ:œParseData-PwO5qœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"YouTubeTranscriptComponent-64xOe","sourceHandle":"{œdataTypeœ:œYouTubeTranscriptComponentœ,œidœ:œYouTubeTranscriptComponent-64xOeœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-D1HB6","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-D1HB6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-D1HB6","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"YouTubeTranscriptComponent","id":"YouTubeTranscriptComponent-64xOe","name":"transcript","output_types":["Data"]}},"id":"reactflow__edge-YouTubeTranscriptComponent-64xOe{œdataTypeœ:œYouTubeTranscriptComponentœ,œidœ:œYouTubeTranscriptComponent-64xOeœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œDataœ]}-ParseData-D1HB6{œfieldNameœ:œdataœ,œidœ:œParseData-D1HB6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"ParseData-D1HB6","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-D1HB6œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-FCttw","targetHandle":"{œfieldNameœ:œtranscriptœ,œidœ:œPrompt-FCttwœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"transcript","id":"Prompt-FCttw","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-D1HB6","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-D1HB6{œdataTypeœ:œParseDataœ,œidœ:œParseData-D1HB6œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-FCttw{œfieldNameœ:œtranscriptœ,œidœ:œPrompt-FCttwœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-E8gVT","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-E8gVTœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"YouTubeVideoInfoExtractor-hGwEv","targetHandle":"{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeVideoInfoExtractor-hGwEvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"youtube_id","id":"YouTubeVideoInfoExtractor-hGwEv","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-E8gVT","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-E8gVT{œdataTypeœ:œTextInputœ,œidœ:œTextInput-E8gVTœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-YouTubeVideoInfoExtractor-hGwEv{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeVideoInfoExtractor-hGwEvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-E8gVT","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-E8gVTœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"YouTubeTranscriptComponent-64xOe","targetHandle":"{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeTranscriptComponent-64xOeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"youtube_id","id":"YouTubeTranscriptComponent-64xOe","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-E8gVT","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-E8gVT{œdataTypeœ:œTextInputœ,œidœ:œTextInput-E8gVTœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-YouTubeTranscriptComponent-64xOe{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeTranscriptComponent-64xOeœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-FCttw","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-FCttwœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"OpenAIModel-RqeC4","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-RqeC4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-RqeC4","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-FCttw","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-FCttw{œdataTypeœ:œPromptœ,œidœ:œPrompt-FCttwœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-RqeC4{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-RqeC4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"OpenAIModel-RqeC4","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-RqeC4œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"TextOutput-wPTnN","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-wPTnNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-wPTnN","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-RqeC4","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-OpenAIModel-RqeC4{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-RqeC4œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-wPTnN{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-wPTnNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""}],"viewport":{"x":182.26346544286076,"y":-66.00184364407471,"zoom":0.8705505632961268}},"description":"This workflow has the objective to summarize a YouTube video","name":"SummarizeWorkflow","last_tested_version":"1.0.9","endpoint_name":null,"is_component":false}