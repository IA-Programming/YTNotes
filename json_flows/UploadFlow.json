{"id":"2a663b76-f6bb-4142-bca8-19a88b46fa16","data":{"nodes":[{"id":"YouTubeTranscriptComponent-JGzpd","type":"genericNode","position":{"x":50.49604254823339,"y":1685.819201410438},"data":{"type":"YouTubeTranscriptComponent","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, BoolInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nfrom youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\r\nimport re\r\n\r\nclass YouTubeTranscriptComponent(Component):\r\n    display_name = \"YouTube Transcript Fetcher\"\r\n    description = \"Fetches transcripts from YouTube videos with optional timestamps.\"\r\n    icon = \"youtube\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"youtube_id\",\r\n            display_name=\"YouTube Video ID\",\r\n            info=\"The ID of the YouTube video.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"include_timestamps\",\r\n            display_name=\"Include Timestamps\",\r\n            info=\"Boolean to include timestamps in the transcript.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Transcript\", name=\"transcript\", method=\"fetch_transcript\"),\r\n    ]\r\n\r\n    preferred_languages = [\r\n        'en', 'es', 'fr', 'de', 'pt', 'ru', 'zh', 'nl', 'ja', 'ko', 'hi', 'tr', \r\n        'pl', 'sv', 'no', 'da', 'fi', 'el', 'th', 'vi'\r\n    ]\r\n\r\n    def fetch_transcript(self) -> Data:\r\n        youtube_id = self.youtube_id\r\n        include_timestamps = self.include_timestamps\r\n\r\n        # Validate YouTube ID\r\n        if not youtube_id:\r\n            self.status = \"YouTube ID is empty.\"\r\n            return Data(data={\"error\": \"YouTube ID is empty.\"})\r\n\r\n        try:\r\n            # Fetch the transcript in the first available preferred language\r\n            transcript = self.get_transcript_in_preferred_language(youtube_id)\r\n\r\n            if transcript is None:\r\n                self.status = \"No transcript found in preferred languages.\"\r\n                return Data(data={\"error\": \"No transcript found in preferred languages.\"})\r\n\r\n            # Process the transcript\r\n            processed_transcript = self.process_transcript(transcript, include_timestamps)\r\n\r\n            self.status = \"Transcript fetched successfully.\"\r\n            return Data(data={\"transcript\": processed_transcript})\r\n\r\n        except VideoUnavailable:\r\n            self.status = \"Video is unavailable.\"\r\n            return Data(data={\"error\": \"Video is unavailable.\"})\r\n        except TranscriptsDisabled:\r\n            self.status = \"Transcripts are disabled for this video.\"\r\n            return Data(data={\"error\": \"Transcripts are disabled for this video.\"})\r\n        except NoTranscriptFound:\r\n            self.status = \"No transcript found for this video.\"\r\n            return Data(data={\"error\": \"No transcript found for this video.\"})\r\n        except Exception as e:\r\n            self.status = f\"An error occurred: {str(e)}\"\r\n            return Data(data={\"error\": f\"An error occurred: {str(e)}\"})\r\n\r\n    def get_transcript_in_preferred_language(self, video_id: str):\r\n        try:\r\n            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n            for lang in self.preferred_languages:\r\n                if transcript_list.find_transcript([lang]):\r\n                    return transcript_list.find_transcript([lang]).fetch()\r\n        except Exception as e:\r\n            self.status = f\"An error occurred while fetching the transcript: {str(e)}\"\r\n            return None\r\n        return None\r\n\r\n    def process_transcript(self, transcript: list, include_timestamps: bool) -> str:\r\n        if include_timestamps:\r\n            return \"\\n\".join([f\"{self.format_timestamp(entry['start'])} - {entry['text']}\" for entry in transcript])\r\n        else:\r\n            return \"\\n\".join([entry['text'] for entry in transcript])\r\n\r\n    def format_timestamp(self, start: float) -> str:\r\n        hours, remainder = divmod(start, 3600)\r\n        minutes, seconds = divmod(remainder, 60)\r\n        if hours > 0:\r\n            return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\r\n        else:\r\n            return f\"{int(minutes):02}:{int(seconds):02}\"\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"include_timestamps":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"include_timestamps","display_name":"Include Timestamps","advanced":false,"dynamic":false,"info":"Boolean to include timestamps in the transcript.","title_case":false,"type":"bool","load_from_db":false},"youtube_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"youtube_id","display_name":"YouTube Video ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The ID of the YouTube video.","title_case":false,"type":"str"}},"description":"Fetches transcripts from YouTube videos with optional timestamps.","icon":"youtube","base_classes":["Data"],"display_name":"String YT Transcript","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"transcript","display_name":"Transcript","method":"fetch_transcript","value":"__UNDEFINED__","cache":true}],"field_order":["youtube_id","include_timestamps"],"beta":false,"edited":true},"id":"YouTubeTranscriptComponent-JGzpd","description":"Fetches transcripts from YouTube videos with optional timestamps.","display_name":"Custom Component"},"selected":false,"width":384,"height":412,"positionAbsolute":{"x":50.49604254823339,"y":1685.819201410438},"dragging":false},{"id":"ParseData-Qz5oC","type":"genericNode","position":{"x":650.726872658676,"y":992.5959020144982},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"YT VIDEO TITLE:\n{title}\n\nYT DESCRIPTION FROM VIDEO:\n{description}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-Qz5oC"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":650.726872658676,"y":992.5959020144982},"dragging":false},{"id":"ParseData-IZYVX","type":"genericNode","position":{"x":636.7678593932276,"y":1593.1483387869976},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"YT VIDEO TRANSCRIPTION:\n{transcript}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-IZYVX"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":636.7678593932276,"y":1593.1483387869976},"dragging":false},{"id":"YouTubeVideoInfoExtractor-cldBc","type":"genericNode","position":{"x":13.113840633682798,"y":729.7768748444595},"data":{"type":"YouTubeVideoInfoExtractor","node":{"template":{"_type":"Component","api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"api_key","display_name":"YouTube API Key","advanced":false,"input_types":[],"dynamic":false,"info":"Your YouTube Data API key.","title_case":false,"password":true,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput, SecretStrInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nimport requests\r\n\r\nclass YouTubeVideoInfoExtractor(Component):\r\n    display_name = \"YouTube Video Info Extractor\"\r\n    description = \"Extracts the title and description of a YouTube video using its ID.\"\r\n    icon = \"youtube\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"youtube_id\",\r\n            display_name=\"YouTube Video ID\",\r\n            info=\"The ID of the YouTube video.\",\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"YouTube API Key\",\r\n            info=\"Your YouTube Data API key.\",\r\n            advanced=False,\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Video Info\", name=\"video_info\", method=\"fetch_video_info\"),\r\n    ]\r\n\r\n    def fetch_video_info(self) -> Data:\r\n        youtube_id = self.youtube_id.strip()\r\n        api_key = self.api_key.strip()  # Use strip directly since SecretStrInput stores the value as string\r\n\r\n        if not youtube_id:\r\n            return Data(data={\"error\": \"YouTube ID cannot be empty\"})\r\n        \r\n        if not api_key:\r\n            return Data(data={\"error\": \"API Key cannot be empty\"})\r\n\r\n        try:\r\n            api_url = f\"https://www.googleapis.com/youtube/v3/videos?id={youtube_id}&part=snippet&key={api_key}\"\r\n            response = requests.get(api_url)\r\n            response.raise_for_status()\r\n\r\n            video_data = response.json()\r\n            if not video_data[\"items\"]:\r\n                return Data(data={\"error\": \"Invalid YouTube ID or video not found\"})\r\n\r\n            snippet = video_data[\"items\"][0][\"snippet\"]\r\n            title = snippet.get(\"title\", \"No Title\")\r\n            description = snippet.get(\"description\", \"\")\r\n\r\n            return Data(data={\"title\": title, \"description\": description})\r\n\r\n        except requests.exceptions.RequestException as e:\r\n            return Data(data={\"error\": str(e)})\r\n        except KeyError as e:\r\n            return Data(data={\"error\": f\"Key error: {str(e)}\"})\r\n        except Exception as e:\r\n            return Data(data={\"error\": f\"An unexpected error occurred: {str(e)}\"})","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"youtube_id":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"youtube_id","display_name":"YouTube Video ID","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The ID of the YouTube video.","title_case":false,"type":"str"}},"description":"Extracts the title and description of a YouTube video using its ID.","icon":"youtube","base_classes":["Data"],"display_name":"Title & Description JSON","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"video_info","display_name":"Video Info","method":"fetch_video_info","value":"__UNDEFINED__","cache":true}],"field_order":["youtube_id","api_key"],"beta":false,"edited":false},"id":"YouTubeVideoInfoExtractor-cldBc","description":"Extracts the title and description of a YouTube video using its ID.","display_name":"Title & Description JSON"},"selected":false,"width":384,"height":430,"dragging":false,"positionAbsolute":{"x":13.113840633682798,"y":729.7768748444595}},{"id":"Prompt-3GTeV","type":"genericNode","position":{"x":1558.7006195788456,"y":1196.4820878053517},"data":{"type":"Prompt","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def post_code_processing(self, new_build_config: dict, current_build_config: dict):\n        \"\"\"\n        This function is called after the code validation is done.\n        \"\"\"\n        frontend_node = super().post_code_processing(new_build_config, current_build_config)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_build_config\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_build_config[\"template\"])\n        return frontend_node\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":"you are going to create a JSON object that has to have the next structure:\n```json\n{jason}\n```\nGiven the main topic that the user wants the json object to be center around to create the list json object  and also having all the YouTube necessary information. create the json list object.\n\nTOPIC TO LEARN: {topic}\n\n{title&description}\n\n{transcriptwtime}\n\n\nRULES TO FOLLOW:\n\n- Don't hallucinate anything that you are not sure about\n- try to not meander off topic","name":"template","display_name":"Template","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"prompt"},"jason":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"jason","display_name":"jason","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"topic":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"topic","display_name":"topic","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"title&description":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"title&description","display_name":"title&description","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"transcriptwtime":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"transcriptwtime","display_name":"transcriptwtime","advanced":false,"input_types":["Message","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["Message"],"name":"","display_name":"Prompt","documentation":"","custom_fields":{"template":["jason","topic","title&description","transcriptwtime"]},"output_types":[],"full_path":null,"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"prompt","hidden":null,"display_name":"Prompt Message","method":"build_prompt","value":"__UNDEFINED__","cache":true}],"field_order":["template"],"beta":false,"error":null,"edited":false},"id":"Prompt-3GTeV","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":702,"positionAbsolute":{"x":1558.7006195788456,"y":1196.4820878053517},"dragging":false},{"id":"OpenAIModel-pD19m","type":"genericNode","position":{"x":2062.9728237273084,"y":985.0065523499488},"data":{"type":"OpenAIModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import (\n    BoolInput,\n    DictInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageInput,\n    SecretStrInput,\n    StrInput,\n)\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.\",\n        ),\n        DropdownInput(\n            name=\"model_name\", display_name=\"Model Name\", advanced=False, options=MODEL_NAMES, value=MODEL_NAMES[0]\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"openai_api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schea is a list of dictionarie s\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.openai_api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n        model_kwargs[\"seed\"] = seed\n\n        if openai_api_key:\n            api_key = SecretStr(openai_api_key)\n        else:\n            api_key = None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature or 0.1,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")  # type: ignore\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})  # type: ignore\n\n        return output  # type: ignore\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"\n        Get a message from an OpenAI exception.\n\n        Args:\n            exception (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")  # type: ignore\n            if message:\n                return message\n        return\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"json_mode":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"json_mode","display_name":"JSON Mode","advanced":true,"dynamic":false,"info":"If True, it will output JSON regardless of passing a schema.","title_case":false,"type":"bool"},"max_tokens":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"2048","name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","title_case":false,"type":"int"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict"},"model_name":{"trace_as_metadata":true,"options":["gpt-4o","gpt-4-turbo","gpt-4-turbo-preview","gpt-4","gpt-3.5-turbo","gpt-3.5-turbo-0125"],"required":false,"placeholder":"","show":true,"value":"gpt-4-turbo-preview","name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_api_base":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"https://litellm-3xlzyox7uq-uc.a.run.app/","name":"openai_api_base","display_name":"OpenAI API Base","advanced":false,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.","title_case":false,"type":"str"},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","title_case":false,"password":true,"type":"str"},"output_schema":{"trace_as_input":true,"list":true,"required":false,"placeholder":"","show":true,"value":{},"name":"output_schema","display_name":"Schema","advanced":true,"dynamic":false,"info":"The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled.","title_case":false,"type":"dict"},"seed":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1,"name":"seed","display_name":"Seed","advanced":true,"dynamic":false,"info":"The seed controls the reproducibility of the job.","title_case":false,"type":"int"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.1,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generates text using OpenAI LLMs.","icon":"OpenAI","base_classes":["LanguageModel","Message"],"display_name":"OpenAI","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","max_tokens","model_kwargs","json_mode","output_schema","model_name","openai_api_base","openai_api_key","temperature","stream","system_message","seed"],"beta":false,"edited":false},"id":"OpenAIModel-pD19m"},"selected":false,"width":384,"height":706,"positionAbsolute":{"x":2062.9728237273084,"y":985.0065523499488},"dragging":false},{"id":"JSONExtractorComponent-i664P","type":"genericNode","position":{"x":2603.938853620843,"y":1354.4238832449696},"data":{"type":"JSONExtractorComponent","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\r\nfrom langflow.inputs import MessageTextInput\r\nfrom langflow.template import Output\r\nfrom langflow.schema import Data\r\nimport re\r\nimport json\r\n\r\nclass JSONExtractorComponent(Component):\r\n    display_name = \"JSON Extractor\"\r\n    description = \"Extracts and cleans a JSON object from a given string input.\"\r\n    icon = \"braces\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"input_string\",\r\n            display_name=\"Input String\",\r\n            info=\"String containing the JSON object.\",\r\n        )\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Clean JSON String\", name=\"clean_json_string\", method=\"extract_and_clean_json\"),\r\n    ]\r\n\r\n    def extract_and_clean_json(self) -> Data:\r\n        input_text = self.input_string\r\n\r\n        try:\r\n            # Extract JSON object from the string\r\n            json_match = re.search(r'\\[.*\\]', input_text, re.DOTALL)\r\n            if not json_match:\r\n                raise ValueError(\"No JSON object found in the input text.\")\r\n\r\n            json_str = json_match.group()\r\n            json_str = json_str.strip()\r\n            # Clean and validate the JSON object\r\n            json_obj = json.loads(json_str)\r\n            cleaned_json_str = json.dumps(json_obj, indent=2)\r\n            self.status = Data(data={\"text\": cleaned_json_str})\r\n            return Data(data={\"text\":cleaned_json_str})\r\n        \r\n        except json.JSONDecodeError as e:\r\n            self.status = f\"JSON decode error: {e}\"\r\n            return Data(data={\"text\": f\"Error: Invalid JSON format - {e}\"})\r\n        \r\n        except ValueError as e:\r\n            self.status = str(e)\r\n            return Data(data={\"text\": f\"Error: {e}\"})\r\n        \r\n        except Exception as e:\r\n            self.status = f\"Unexpected error: {e}\"\r\n            return Data(data={\"text\": f\"Error: An unexpected error occurred - {e}\"})\r\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_string":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_string","display_name":"Input String","advanced":false,"input_types":["Message"],"dynamic":false,"info":"String containing the JSON object.","title_case":false,"type":"str"}},"description":"Extracts and cleans a JSON object from a given string input.","icon":"braces","base_classes":["Data"],"display_name":"Json text objext extractor","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"clean_json_string","display_name":"Clean JSON String","method":"extract_and_clean_json","value":"__UNDEFINED__","cache":true}],"field_order":["input_string"],"beta":false,"edited":true},"id":"JSONExtractorComponent-i664P","description":"Extracts and cleans a JSON object from a given string input.","display_name":"Json text objext extractor"},"selected":false,"width":384,"height":336,"dragging":false,"positionAbsolute":{"x":2603.938853620843,"y":1354.4238832449696}},{"id":"CustomComponent-b2fZU","type":"genericNode","position":{"x":-1212.2050507098531,"y":1076.0114904798234},"data":{"type":"CustomComponent","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput\nfrom langflow.template import Output\nfrom langflow.schema import Data\nimport json\n\n\nclass CustomComponent(Component):\n    display_name = \"Data metadata object\"\n    description = \"Create a Data object to save in a Vectorstore\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"hard-drive\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(name=\"text_input\", display_name=\"text_input\", value=\"text_input\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        data_dict = json.loads(self.text_input)\n        video_id = data_dict.get('video_id')\n        topic = data_dict.get('topic')\n        user_id = data_dict.get('user_id')\n        data = Data(video_id=video_id, topic=topic, user_id=user_id)\n        self.status = data\n        return data","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"text_input":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"text_input","display_name":"text_input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"}},"description":"Create a Data object to save in a Vectorstore","icon":"hard-drive","base_classes":["Data"],"display_name":"Data metadata creator","documentation":"http://docs.langflow.org/components/custom","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"output","display_name":"Output","method":"build_output","value":"__UNDEFINED__","cache":true}],"field_order":["text_input"],"beta":false,"edited":true},"id":"CustomComponent-b2fZU","description":"Create a Data object to save in a Vectorstore","display_name":"Custom Component"},"selected":false,"width":384,"height":308,"positionAbsolute":{"x":-1212.2050507098531,"y":1076.0114904798234},"dragging":false},{"id":"ParseData-cidk3","type":"genericNode","position":{"x":-642.691235564097,"y":669.7802914702668},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{video_id}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-cidk3"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":-642.691235564097,"y":669.7802914702668},"dragging":false},{"id":"TextInput-NpngE","type":"genericNode","position":{"x":-1764.0638722435388,"y":1094.0978698006975},"data":{"type":"TextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{\"user_id\": \"123456\", \"video_id\": \"yj-wSRJwrrc\", \"topic\": \"What is Pydantic and which are their main uses in the AI field?\"}","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str"}},"description":"Get text inputs from the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Input","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextInput-NpngE"},"selected":false,"width":384,"height":308,"positionAbsolute":{"x":-1764.0638722435388,"y":1094.0978698006975},"dragging":false},{"id":"ParseData-Aopyo","type":"genericNode","position":{"x":-628.5575306850924,"y":1325.0199791888915},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{topic}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-Aopyo"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":-628.5575306850924,"y":1325.0199791888915},"dragging":false},{"id":"MergeData-7SrPw","type":"genericNode","position":{"x":3085.9501826434594,"y":1817.9335692017305},"data":{"type":"MergeData","node":{"template":{"_type":"CustomComponent","data":{"type":"Data","required":true,"placeholder":"","list":true,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"data","display_name":"Data","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass MergeDataComponent(CustomComponent):\n    display_name = \"Merge Data\"\n    description = \"Combines multiple data sources into a single unified Data object.\"\n    beta: bool = True\n    name = \"MergeData\"\n\n    field_config = {\n        \"data\": {\"display_name\": \"Data\"},\n    }\n\n    def build(self, data: list[Data]) -> Data:\n        if not data:\n            return Data()\n        if len(data) == 1:\n            return data[0]\n        merged_data = Data()\n        for value in data:\n            if merged_data is None:\n                merged_data = value\n            else:\n                merged_data += value\n        self.status = merged_data\n        return merged_data\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Combines multiple data sources into a single unified Data object.","base_classes":["Data"],"display_name":"Merge Data","documentation":"","custom_fields":{"data":null},"output_types":["Data"],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"data","hidden":null,"display_name":"Data","method":null,"value":"__UNDEFINED__","cache":true}],"field_order":["data"],"beta":true,"edited":false},"id":"MergeData-7SrPw"},"selected":false,"width":384,"height":290,"dragging":false,"positionAbsolute":{"x":3085.9501826434594,"y":1817.9335692017305}},{"id":"CustomComponent-QhEPl","type":"genericNode","position":{"x":1109.9001624045127,"y":910.8365833495749},"data":{"type":"CTextInput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import Output\nfrom langflow.schema.message import Message\n\n\nclass CustomTextInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Default text input to prompt\"\n    icon = \"book-type\"\n    name = \"CTextInput\"\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=\"\"\"[{\"time_stamp\": \"hh:mm:ss or mm:ss\", \"title_section\": \"descriptive section sub-title\", \"summary\": \"short summary to rescue between the start of this time stamp and the next one\"},...]\"\"\",\n        )\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false}},"description":"Default text input to prompt","icon":"book-type","base_classes":["Message"],"display_name":"Custom Component","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":[],"beta":false,"edited":true},"id":"CustomComponent-QhEPl","description":"Default text input to prompt","display_name":"Custom Component"},"selected":false,"width":384,"height":218,"dragging":false,"positionAbsolute":{"x":1109.9001624045127,"y":910.8365833495749}},{"id":"ParseData-ByMh3","type":"genericNode","position":{"x":653.6108004395878,"y":431.9035285657443},"data":{"type":"ParseData","node":{"template":{"_type":"Component","data":{"trace_as_input":true,"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"data","display_name":"Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"The data to convert to text.","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"sep":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"\n","name":"sep","display_name":"Separator","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"str"},"template":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"{title}","name":"template","display_name":"Template","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.","title_case":false,"type":"str"}},"description":"Convert Data into plain text following a specified template.","icon":"braces","base_classes":["Message"],"display_name":"Parse Data","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"parse_data","value":"__UNDEFINED__","cache":true}],"field_order":["data","template","sep"],"beta":false,"edited":false},"id":"ParseData-ByMh3"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":653.6108004395878,"y":431.9035285657443},"dragging":false},{"id":"CustomComponent-Zdw7Q","type":"genericNode","position":{"x":3098.6547847078264,"y":951.304008868813},"data":{"type":"CustomTextID","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom typing import Any, Optional\nfrom langflow.custom import CustomComponent\nfrom langflow.schema.dotdict import dotdict\n\nclass CustomTextIDComponent(TextComponent, CustomComponent):\n    display_name = \"Custom Text ID Component\"\n    description = \"Processes text input and generates a unique ID.\"\n    icon = \"file-type-2\"\n    name = \"CustomTextID\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text Output\", name=\"unique_id\", method=\"generate_unique_id\"),\n    ]\n\n    def generate_unique_id(self) -> str:\n        input_text = self.input_value\n        combined_message = str(input_text)\n        return combined_message\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: Optional[str] = None):\n        if field_name == \"unique_id\":\n            build_config[field_name][\"value\"] = str(uuid.uuid4())\n        return build_config\n\n    def build_config(self):\n        return {\n            \"unique_id\": {\n                \"display_name\": \"Unique ID\",\n                \"refresh_button\": True,\n            }\n        }\n\n    def build(self, unique_id: str) -> str:\n        return unique_id\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as input.","title_case":false,"type":"str"}},"description":"Processes text input and generates a unique ID.","icon":"file-type-2","base_classes":["Text"],"display_name":"Custom Component","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Text"],"selected":"Text","name":"unique_id","display_name":"Text Output","method":"generate_unique_id","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":true},"id":"CustomComponent-Zdw7Q","description":"Processes text input and generates a unique ID.","display_name":"Custom Component"},"selected":false,"width":384,"height":308,"positionAbsolute":{"x":3098.6547847078264,"y":951.304008868813},"dragging":false},{"id":"UpdateData-DprRI","type":"genericNode","position":{"x":3620.9747562256375,"y":1517.110164023292},"data":{"type":"UpdateData","node":{"template":{"_type":"CustomComponent","data":{"type":"Data","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"data","display_name":"Data","advanced":false,"dynamic":false,"info":"The record to update.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.custom import CustomComponent\nfrom langflow.schema import Data\n\n\nclass UpdateDataComponent(CustomComponent):\n    display_name = \"Update Data\"\n    description = \"Update Data with text-based key/value pairs, similar to updating a Python dictionary.\"\n    name = \"UpdateData\"\n\n    def build_config(self):\n        return {\n            \"data\": {\n                \"display_name\": \"Data\",\n                \"info\": \"The record to update.\",\n            },\n            \"new_data\": {\n                \"display_name\": \"New Data\",\n                \"info\": \"The new data to update the record with.\",\n                \"input_types\": [\"Text\"],\n            },\n        }\n\n    def build(\n        self,\n        data: Data,\n        new_data: dict,\n    ) -> Data:\n        \"\"\"\n        Updates a record with new data.\n\n        Args:\n            record (Data): The record to update.\n            new_data (dict): The new data to update the record with.\n\n        Returns:\n            Data: The updated record.\n        \"\"\"\n        data.data.update(new_data)\n        self.status = data\n        return data\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"new_data":{"type":"dict","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"new_data","display_name":"New Data","advanced":false,"input_types":["Text"],"dynamic":false,"info":"The new data to update the record with.","load_from_db":false,"title_case":false,"value":{"video_title":""}}},"description":"Update Data with text-based key/value pairs, similar to updating a Python dictionary.","base_classes":["Data"],"display_name":"Update Data","documentation":"","custom_fields":{"data":null,"new_data":null},"output_types":["Data"],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Data"],"selected":"Data","name":"data","hidden":null,"display_name":"Data","method":null,"value":"__UNDEFINED__","cache":true}],"field_order":[],"beta":false,"edited":false},"id":"UpdateData-DprRI"},"selected":false,"width":384,"height":384,"positionAbsolute":{"x":3620.9747562256375,"y":1517.110164023292},"dragging":false},{"id":"OpenAIEmbeddings-Pvdwo","type":"genericNode","position":{"x":3684.395446507491,"y":1945.0927925701321},"data":{"type":"OpenAIEmbeddings","node":{"template":{"_type":"Component","chunk_size":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":1000,"name":"chunk_size","display_name":"Chunk Size","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"},"client":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"client","display_name":"Client","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=[\n                \"text-embedding-3-small\",\n                \"text-embedding-3-large\",\n                \"text-embedding-ada-002\",\n            ],\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"default_headers":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"default_headers","display_name":"Default Headers","advanced":true,"dynamic":false,"info":"Default headers to use for the API request.","title_case":false,"type":"dict"},"default_query":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"default_query","display_name":"Default Query","advanced":true,"dynamic":false,"info":"Default query parameters to use for the API request.","title_case":false,"type":"dict"},"deployment":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"deployment","display_name":"Deployment","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"dimensions":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"dimensions","display_name":"Dimensions","advanced":true,"dynamic":false,"info":"The number of dimensions the resulting output embeddings should have. Only supported by certain models.","title_case":false,"type":"int"},"embedding_ctx_length":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"768","name":"embedding_ctx_length","display_name":"Embedding Context Length","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"int"},"max_retries":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"0","name":"max_retries","display_name":"Max Retries","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"int"},"model":{"trace_as_metadata":true,"options":["text-embedding-3-small","text-embedding-3-large","text-embedding-ada-002"],"required":false,"placeholder":"","show":true,"value":"text-embedding-3-small","name":"model","display_name":"Model","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"model_kwargs":{"trace_as_input":true,"list":false,"required":false,"placeholder":"","show":true,"value":{},"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"dict"},"openai_api_base":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_base","display_name":"OpenAI API Base","advanced":false,"input_types":[],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str"},"openai_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"input_types":[],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str"},"openai_api_type":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_type","display_name":"OpenAI API Type","advanced":true,"input_types":[],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str"},"openai_api_version":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_api_version","display_name":"OpenAI API Version","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_organization":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_organization","display_name":"OpenAI Organization","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"openai_proxy":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"openai_proxy","display_name":"OpenAI Proxy","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"request_timeout":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"request_timeout","display_name":"Request Timeout","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"float"},"show_progress_bar":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"show_progress_bar","display_name":"Show Progress Bar","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"},"skip_empty":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"skip_empty","display_name":"Skip Empty","advanced":true,"dynamic":false,"info":"","title_case":false,"type":"bool"},"tiktoken_enable":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":true,"name":"tiktoken_enable","display_name":"TikToken Enable","advanced":true,"dynamic":false,"info":"If False, you must have transformers installed.","title_case":false,"type":"bool"},"tiktoken_model_name":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"tiktoken_model_name","display_name":"TikToken Model Name","advanced":true,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"}},"description":"Generate embeddings using OpenAI models.","icon":"OpenAI","base_classes":["Embeddings"],"display_name":"OpenAI Embeddings","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Embeddings"],"selected":"Embeddings","name":"embeddings","display_name":"Embeddings","method":"build_embeddings","value":"__UNDEFINED__","cache":true}],"field_order":["default_headers","default_query","chunk_size","client","deployment","embedding_ctx_length","max_retries","model","model_kwargs","openai_api_base","openai_api_key","openai_api_type","openai_api_version","openai_organization","openai_proxy","request_timeout","show_progress_bar","skip_empty","tiktoken_model_name","tiktoken_enable","dimensions"],"beta":false,"edited":false},"id":"OpenAIEmbeddings-Pvdwo"},"selected":false,"width":384,"height":573,"positionAbsolute":{"x":3684.395446507491,"y":1945.0927925701321},"dragging":false},{"id":"RetrievalQA-iIpv5","type":"genericNode","position":{"x":5352.221442376659,"y":1712.1400315357082},"data":{"type":"RetrievalQA","node":{"template":{"_type":"Component","llm":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"value":"","name":"llm","display_name":"Language Model","advanced":false,"input_types":["LanguageModel"],"dynamic":false,"info":"","title_case":false,"type":"other"},"memory":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"memory","display_name":"Memory","advanced":false,"input_types":["BaseChatMemory"],"dynamic":false,"info":"","title_case":false,"type":"other"},"retriever":{"trace_as_metadata":true,"list":false,"required":true,"placeholder":"","show":true,"value":"","name":"retriever","display_name":"Retriever","advanced":false,"input_types":["Retriever"],"dynamic":false,"info":"","title_case":false,"type":"other"},"chain_type":{"trace_as_metadata":true,"options":["Stuff","Map Reduce","Refine","Map Rerank"],"required":false,"placeholder":"","show":true,"value":"Stuff","name":"chain_type","display_name":"Chain Type","advanced":true,"dynamic":false,"info":"Chain type to use.","title_case":false,"type":"str"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain.chains import RetrievalQA\n\nfrom langflow.base.chains.model import LCChainComponent\nfrom langflow.field_typing import Message\nfrom langflow.inputs import HandleInput, MultilineInput, BoolInput, DropdownInput\n\n\nclass RetrievalQAComponent(LCChainComponent):\n    display_name = \"Retrieval QA\"\n    description = \"Chain for question-answering querying sources from a retriever.\"\n    name = \"RetrievalQA\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\", display_name=\"Input\", info=\"The input value to pass to the chain.\", required=True\n        ),\n        DropdownInput(\n            name=\"chain_type\",\n            display_name=\"Chain Type\",\n            info=\"Chain type to use.\",\n            options=[\"Stuff\", \"Map Reduce\", \"Refine\", \"Map Rerank\"],\n            value=\"Stuff\",\n            advanced=True,\n        ),\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        HandleInput(name=\"retriever\", display_name=\"Retriever\", input_types=[\"Retriever\"], required=True),\n        HandleInput(\n            name=\"memory\",\n            display_name=\"Memory\",\n            input_types=[\"BaseChatMemory\"],\n        ),\n        BoolInput(\n            name=\"return_source_documents\",\n            display_name=\"Return Source Documents\",\n            value=False,\n        ),\n    ]\n\n    def invoke_chain(self) -> Message:\n        chain_type = self.chain_type.lower().replace(\" \", \"_\")\n        if self.memory:\n            self.memory.input_key = \"query\"\n            self.memory.output_key = \"result\"\n\n        runnable = RetrievalQA.from_chain_type(\n            llm=self.llm,\n            chain_type=chain_type,\n            retriever=self.retriever,\n            memory=self.memory,\n            # always include to help debugging\n            #\n            return_source_documents=True,\n        )\n\n        result = runnable.invoke({\"query\": self.input_value})\n\n        source_docs = self.to_data(result.get(\"source_documents\", []))\n        result_str = str(result.get(\"result\", \"\"))\n        if self.return_source_documents and len(source_docs):\n            references_str = self.create_references_from_data(source_docs)\n            result_str = \"\\n\".join([result_str, references_str])\n        # put the entire result to debug history, query and content\n        self.status = {**result, \"source_documents\": source_docs, \"output\": result_str}\n        return result_str\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"The input value to pass to the chain.","title_case":false,"type":"str"},"return_source_documents":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"return_source_documents","display_name":"Return Source Documents","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"bool"}},"description":"Chain for question-answering querying sources from a retriever.","base_classes":["Message"],"display_name":"Retrieval QA","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"invoke_chain","value":"__UNDEFINED__","cache":true}],"field_order":["input_value","chain_type","llm","retriever","memory","return_source_documents"],"beta":false,"edited":false},"id":"RetrievalQA-iIpv5"},"selected":false,"width":384,"height":556,"positionAbsolute":{"x":5352.221442376659,"y":1712.1400315357082},"dragging":false},{"id":"TextOutput-X4x75","type":"genericNode","position":{"x":5911.9631261986715,"y":1794.6865073971724},"data":{"type":"TextOutput","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langflow.base.io.text import TextComponent\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Text","advanced":false,"input_types":["Message"],"dynamic":false,"info":"Text to be passed as output.","title_case":false,"type":"str"}},"description":"Display a text output in the Playground.","icon":"type","base_classes":["Message"],"display_name":"Text Output","documentation":"","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true}],"field_order":["input_value"],"beta":false,"edited":false},"id":"TextOutput-X4x75"},"selected":false,"width":384,"height":308},{"id":"CohereModel-p8Sdn","type":"genericNode","position":{"x":4831.870295811875,"y":1587.5627814919444},"data":{"type":"CohereModel","node":{"template":{"_type":"Component","code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_cohere import ChatCohere\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.constants import STREAM_INFO_TEXT\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.io import BoolInput, FloatInput, MessageInput, SecretStrInput, StrInput\n\n\nclass CohereComponent(LCModelComponent):\n    display_name = \"Cohere\"\n    description = \"Generate text using Cohere LLMs.\"\n    documentation = \"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere\"\n    icon = \"Cohere\"\n    name = \"CohereModel\"\n\n    inputs = [\n        SecretStrInput(\n            name=\"cohere_api_key\",\n            display_name=\"Cohere API Key\",\n            info=\"The Cohere API Key to use for the Cohere model.\",\n            advanced=False,\n            value=\"COHERE_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.75),\n        MessageInput(name=\"input_value\", display_name=\"Input\"),\n        BoolInput(name=\"stream\", display_name=\"Stream\", info=STREAM_INFO_TEXT, advanced=True),\n        StrInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"System message to pass to the model.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        cohere_api_key = self.cohere_api_key\n        temperature = self.temperature\n\n        if cohere_api_key:\n            api_key = SecretStr(cohere_api_key)\n        else:\n            api_key = None\n\n        output = ChatCohere(\n            temperature=temperature or 0.75,\n            cohere_api_key=api_key,\n        )\n\n        return output  # type: ignore\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"cohere_api_key":{"load_from_db":false,"required":false,"placeholder":"","show":true,"value":"","name":"cohere_api_key","display_name":"Cohere API Key","advanced":false,"input_types":[],"dynamic":false,"info":"The Cohere API Key to use for the Cohere model.","title_case":false,"password":true,"type":"str"},"input_value":{"trace_as_input":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"input_value","display_name":"Input","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"stream":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","title_case":false,"type":"bool"},"system_message":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","title_case":false,"type":"str"},"temperature":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":0.75,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"float"}},"description":"Generate text using Cohere LLMs.","icon":"Cohere","base_classes":["LanguageModel","Message"],"display_name":"Cohere","documentation":"https://python.langchain.com/docs/modules/model_io/models/llms/integrations/cohere","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Message"],"selected":"Message","name":"text_output","display_name":"Text","method":"text_response","value":"__UNDEFINED__","cache":true},{"types":["LanguageModel"],"selected":"LanguageModel","name":"model_output","display_name":"Language Model","method":"build_model","value":"__UNDEFINED__","cache":true}],"field_order":["cohere_api_key","temperature","input_value","stream","system_message"],"beta":false,"edited":false},"id":"CohereModel-p8Sdn"},"selected":false,"width":384,"height":535,"positionAbsolute":{"x":4831.870295811875,"y":1587.5627814919444},"dragging":false},{"id":"SupabaseVectorStore-7rVC0","type":"genericNode","position":{"x":4216.299249925576,"y":1500.9073498199746},"data":{"type":"SupabaseVectorStore","node":{"template":{"_type":"Component","embedding":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"embedding","display_name":"Embedding","advanced":false,"input_types":["Embeddings"],"dynamic":false,"info":"","title_case":false,"type":"other"},"ingest_data":{"trace_as_input":true,"trace_as_metadata":true,"list":true,"required":false,"placeholder":"","show":true,"value":"","name":"ingest_data","display_name":"Ingest Data","advanced":false,"input_types":["Data"],"dynamic":false,"info":"","title_case":false,"type":"other"},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import List\n\nfrom langchain_community.vectorstores import SupabaseVectorStore\nfrom supabase.client import Client, create_client\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent\nfrom langflow.helpers.data import docs_to_data\nfrom langflow.io import HandleInput, IntInput, StrInput, SecretStrInput, DataInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass SupabaseVectorStoreComponent(LCVectorStoreComponent):\n    display_name = \"Supabase\"\n    description = \"Supabase Vector Store with search capabilities\"\n    documentation = \"https://python.langchain.com/v0.2/docs/integrations/vectorstores/supabase/\"\n    name = \"SupabaseVectorStore\"\n    icon = \"Supabase\"\n\n    inputs = [\n        StrInput(name=\"supabase_url\", display_name=\"Supabase URL\", required=True),\n        SecretStrInput(name=\"supabase_service_key\", display_name=\"Supabase Service Key\", required=True),\n        StrInput(name=\"table_name\", display_name=\"Table Name\", advanced=True),\n        StrInput(name=\"query_name\", display_name=\"Query Name\"),\n        MultilineInput(name=\"search_query\", display_name=\"Search Query\"),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            value=4,\n            advanced=True,\n        ),\n    ]\n\n    def build_vector_store(self) -> SupabaseVectorStore:\n        return self._build_supabase()\n\n    def _build_supabase(self) -> SupabaseVectorStore:\n        supabase: Client = create_client(self.supabase_url, supabase_key=self.supabase_service_key)\n\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                documents.append(_input)\n\n        if documents:\n            supabase_vs = SupabaseVectorStore.from_documents(\n                documents=documents,\n                embedding=self.embedding,\n                query_name=self.query_name,\n                client=supabase,\n                table_name=self.table_name,\n            )\n        else:\n            supabase_vs = SupabaseVectorStore(\n                client=supabase,\n                embedding=self.embedding,\n                table_name=self.table_name,\n                query_name=self.query_name,\n            )\n\n        return supabase_vs\n\n    def search_documents(self) -> List[Data]:\n        vector_store = self._build_supabase()\n\n        if self.search_query and isinstance(self.search_query, str) and self.search_query.strip():\n            docs = vector_store.similarity_search(\n                query=self.search_query,\n                k=self.number_of_results,\n            )\n\n            data = docs_to_data(docs)\n            self.status = data\n            return data\n        else:\n            return []\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"number_of_results":{"trace_as_metadata":true,"list":false,"required":false,"placeholder":"","show":true,"value":4,"name":"number_of_results","display_name":"Number of Results","advanced":true,"dynamic":false,"info":"Number of results to return.","title_case":false,"type":"int"},"query_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"match_videos_docs","name":"query_name","display_name":"Query Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"search_query":{"trace_as_input":true,"multiline":true,"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"","name":"search_query","display_name":"Search Query","advanced":false,"input_types":["Message"],"dynamic":false,"info":"","title_case":false,"type":"str"},"supabase_service_key":{"load_from_db":false,"required":true,"placeholder":"","show":true,"value":"","name":"supabase_service_key","display_name":"Supabase Service Key","advanced":false,"input_types":[],"dynamic":false,"info":"","title_case":false,"password":true,"type":"str"},"supabase_url":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":true,"placeholder":"","show":true,"value":"https://fycizuevexasthdbdmom.supabase.co","name":"supabase_url","display_name":"Supabase URL","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"},"table_name":{"trace_as_metadata":true,"load_from_db":false,"list":false,"required":false,"placeholder":"","show":true,"value":"videos_docs","name":"table_name","display_name":"Table Name","advanced":false,"dynamic":false,"info":"","title_case":false,"type":"str"}},"description":"Supabase Vector Store with search capabilities","icon":"Supabase","base_classes":["Data","Retriever","VectorStore"],"display_name":"Supabase","documentation":"https://python.langchain.com/v0.2/docs/integrations/vectorstores/supabase/","custom_fields":{},"output_types":[],"pinned":false,"conditional_paths":[],"frozen":false,"outputs":[{"types":["Retriever"],"selected":"Retriever","name":"base_retriever","display_name":"Retriever","method":"build_base_retriever","value":"__UNDEFINED__","cache":true},{"types":["Data"],"selected":"Data","name":"search_results","display_name":"Search Results","method":"search_documents","value":"__UNDEFINED__","cache":true},{"types":["VectorStore"],"selected":"VectorStore","name":"vector_store","display_name":"Vector Store","method":"cast_vector_store","value":"__UNDEFINED__","cache":true}],"field_order":["supabase_url","supabase_service_key","table_name","query_name","search_query","ingest_data","embedding","number_of_results"],"beta":false,"edited":false},"id":"SupabaseVectorStore-7rVC0"},"selected":true,"width":384,"height":850,"positionAbsolute":{"x":4216.299249925576,"y":1500.9073498199746},"dragging":false}],"edges":[{"source":"YouTubeTranscriptComponent-JGzpd","sourceHandle":"{œdataTypeœ:œYouTubeTranscriptComponentœ,œidœ:œYouTubeTranscriptComponent-JGzpdœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-IZYVX","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-IZYVXœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-IZYVX","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"YouTubeTranscriptComponent","id":"YouTubeTranscriptComponent-JGzpd","name":"transcript","output_types":["Data"]}},"id":"reactflow__edge-YouTubeTranscriptComponent-JGzpd{œdataTypeœ:œYouTubeTranscriptComponentœ,œidœ:œYouTubeTranscriptComponent-JGzpdœ,œnameœ:œtranscriptœ,œoutput_typesœ:[œDataœ]}-ParseData-IZYVX{œfieldNameœ:œdataœ,œidœ:œParseData-IZYVXœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"YouTubeVideoInfoExtractor-cldBc","sourceHandle":"{œdataTypeœ:œYouTubeVideoInfoExtractorœ,œidœ:œYouTubeVideoInfoExtractor-cldBcœ,œnameœ:œvideo_infoœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-Qz5oC","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-Qz5oCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-Qz5oC","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"YouTubeVideoInfoExtractor","id":"YouTubeVideoInfoExtractor-cldBc","name":"video_info","output_types":["Data"]}},"id":"reactflow__edge-YouTubeVideoInfoExtractor-cldBc{œdataTypeœ:œYouTubeVideoInfoExtractorœ,œidœ:œYouTubeVideoInfoExtractor-cldBcœ,œnameœ:œvideo_infoœ,œoutput_typesœ:[œDataœ]}-ParseData-Qz5oC{œfieldNameœ:œdataœ,œidœ:œParseData-Qz5oCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"ParseData-Qz5oC","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-Qz5oCœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-3GTeV","targetHandle":"{œfieldNameœ:œtitle&descriptionœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"title&description","id":"Prompt-3GTeV","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-Qz5oC","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-Qz5oC{œdataTypeœ:œParseDataœ,œidœ:œParseData-Qz5oCœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-3GTeV{œfieldNameœ:œtitle&descriptionœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"ParseData-IZYVX","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-IZYVXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-3GTeV","targetHandle":"{œfieldNameœ:œtranscriptwtimeœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"transcriptwtime","id":"Prompt-3GTeV","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-IZYVX","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-IZYVX{œdataTypeœ:œParseDataœ,œidœ:œParseData-IZYVXœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-3GTeV{œfieldNameœ:œtranscriptwtimeœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"Prompt-3GTeV","sourceHandle":"{œdataTypeœ:œPromptœ,œidœ:œPrompt-3GTeVœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}","target":"OpenAIModel-pD19m","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pD19mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-pD19m","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"Prompt","id":"Prompt-3GTeV","name":"prompt","output_types":["Message"]}},"id":"reactflow__edge-Prompt-3GTeV{œdataTypeœ:œPromptœ,œidœ:œPrompt-3GTeVœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-pD19m{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-pD19mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"OpenAIModel-pD19m","sourceHandle":"{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pD19mœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}","target":"JSONExtractorComponent-i664P","targetHandle":"{œfieldNameœ:œinput_stringœ,œidœ:œJSONExtractorComponent-i664Pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_string","id":"JSONExtractorComponent-i664P","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"OpenAIModel","id":"OpenAIModel-pD19m","name":"text_output","output_types":["Message"]}},"id":"reactflow__edge-OpenAIModel-pD19m{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-pD19mœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-JSONExtractorComponent-i664P{œfieldNameœ:œinput_stringœ,œidœ:œJSONExtractorComponent-i664Pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"TextInput-NpngE","sourceHandle":"{œdataTypeœ:œTextInputœ,œidœ:œTextInput-NpngEœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"CustomComponent-b2fZU","targetHandle":"{œfieldNameœ:œtext_inputœ,œidœ:œCustomComponent-b2fZUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"text_input","id":"CustomComponent-b2fZU","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"TextInput","id":"TextInput-NpngE","name":"text","output_types":["Message"]}},"id":"reactflow__edge-TextInput-NpngE{œdataTypeœ:œTextInputœ,œidœ:œTextInput-NpngEœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-b2fZU{œfieldNameœ:œtext_inputœ,œidœ:œCustomComponent-b2fZUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"ParseData-cidk3","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-cidk3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"YouTubeVideoInfoExtractor-cldBc","targetHandle":"{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeVideoInfoExtractor-cldBcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"youtube_id","id":"YouTubeVideoInfoExtractor-cldBc","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-cidk3","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-cidk3{œdataTypeœ:œParseDataœ,œidœ:œParseData-cidk3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-YouTubeVideoInfoExtractor-cldBc{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeVideoInfoExtractor-cldBcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"ParseData-cidk3","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-cidk3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"YouTubeTranscriptComponent-JGzpd","targetHandle":"{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeTranscriptComponent-JGzpdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"youtube_id","id":"YouTubeTranscriptComponent-JGzpd","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-cidk3","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-cidk3{œdataTypeœ:œParseDataœ,œidœ:œParseData-cidk3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-YouTubeTranscriptComponent-JGzpd{œfieldNameœ:œyoutube_idœ,œidœ:œYouTubeTranscriptComponent-JGzpdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"ParseData-Aopyo","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-Aopyoœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-3GTeV","targetHandle":"{œfieldNameœ:œtopicœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"topic","id":"Prompt-3GTeV","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-Aopyo","name":"text","output_types":["Message"]}},"id":"reactflow__edge-ParseData-Aopyo{œdataTypeœ:œParseDataœ,œidœ:œParseData-Aopyoœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-3GTeV{œfieldNameœ:œtopicœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"CustomComponent-b2fZU","sourceHandle":"{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b2fZUœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-Aopyo","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-Aopyoœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-Aopyo","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-b2fZU","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-b2fZU{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b2fZUœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-ParseData-Aopyo{œfieldNameœ:œdataœ,œidœ:œParseData-Aopyoœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"CustomComponent-b2fZU","sourceHandle":"{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b2fZUœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-cidk3","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-cidk3œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-cidk3","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-b2fZU","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-b2fZU{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b2fZUœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-ParseData-cidk3{œfieldNameœ:œdataœ,œidœ:œParseData-cidk3œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"JSONExtractorComponent-i664P","sourceHandle":"{œdataTypeœ:œJSONExtractorComponentœ,œidœ:œJSONExtractorComponent-i664Pœ,œnameœ:œclean_json_stringœ,œoutput_typesœ:[œDataœ]}","target":"MergeData-7SrPw","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œMergeData-7SrPwœ,œinputTypesœ:null,œtypeœ:œDataœ}","data":{"targetHandle":{"fieldName":"data","id":"MergeData-7SrPw","inputTypes":null,"type":"Data"},"sourceHandle":{"dataType":"JSONExtractorComponent","id":"JSONExtractorComponent-i664P","name":"clean_json_string","output_types":["Data"]}},"id":"reactflow__edge-JSONExtractorComponent-i664P{œdataTypeœ:œJSONExtractorComponentœ,œidœ:œJSONExtractorComponent-i664Pœ,œnameœ:œclean_json_stringœ,œoutput_typesœ:[œDataœ]}-MergeData-7SrPw{œfieldNameœ:œdataœ,œidœ:œMergeData-7SrPwœ,œinputTypesœ:null,œtypeœ:œDataœ}","className":""},{"source":"CustomComponent-b2fZU","sourceHandle":"{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b2fZUœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}","target":"MergeData-7SrPw","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œMergeData-7SrPwœ,œinputTypesœ:null,œtypeœ:œDataœ}","data":{"targetHandle":{"fieldName":"data","id":"MergeData-7SrPw","inputTypes":null,"type":"Data"},"sourceHandle":{"dataType":"CustomComponent","id":"CustomComponent-b2fZU","name":"output","output_types":["Data"]}},"id":"reactflow__edge-CustomComponent-b2fZU{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-b2fZUœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-MergeData-7SrPw{œfieldNameœ:œdataœ,œidœ:œMergeData-7SrPwœ,œinputTypesœ:null,œtypeœ:œDataœ}","className":""},{"source":"CustomComponent-QhEPl","sourceHandle":"{œdataTypeœ:œCTextInputœ,œidœ:œCustomComponent-QhEPlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"Prompt-3GTeV","targetHandle":"{œfieldNameœ:œjasonœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"jason","id":"Prompt-3GTeV","inputTypes":["Message","Text"],"type":"str"},"sourceHandle":{"dataType":"CTextInput","id":"CustomComponent-QhEPl","name":"text","output_types":["Message"]}},"id":"reactflow__edge-CustomComponent-QhEPl{œdataTypeœ:œCTextInputœ,œidœ:œCustomComponent-QhEPlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-3GTeV{œfieldNameœ:œjasonœ,œidœ:œPrompt-3GTeVœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}","className":""},{"source":"YouTubeVideoInfoExtractor-cldBc","sourceHandle":"{œdataTypeœ:œYouTubeVideoInfoExtractorœ,œidœ:œYouTubeVideoInfoExtractor-cldBcœ,œnameœ:œvideo_infoœ,œoutput_typesœ:[œDataœ]}","target":"ParseData-ByMh3","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œParseData-ByMh3œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"data","id":"ParseData-ByMh3","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"YouTubeVideoInfoExtractor","id":"YouTubeVideoInfoExtractor-cldBc","name":"video_info","output_types":["Data"]}},"id":"reactflow__edge-YouTubeVideoInfoExtractor-cldBc{œdataTypeœ:œYouTubeVideoInfoExtractorœ,œidœ:œYouTubeVideoInfoExtractor-cldBcœ,œnameœ:œvideo_infoœ,œoutput_typesœ:[œDataœ]}-ParseData-ByMh3{œfieldNameœ:œdataœ,œidœ:œParseData-ByMh3œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"MergeData-7SrPw","sourceHandle":"{œdataTypeœ:œMergeDataœ,œidœ:œMergeData-7SrPwœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}","target":"UpdateData-DprRI","targetHandle":"{œfieldNameœ:œdataœ,œidœ:œUpdateData-DprRIœ,œinputTypesœ:null,œtypeœ:œDataœ}","data":{"targetHandle":{"fieldName":"data","id":"UpdateData-DprRI","inputTypes":null,"type":"Data"},"sourceHandle":{"dataType":"MergeData","id":"MergeData-7SrPw","name":"data","output_types":["Data"]}},"id":"reactflow__edge-MergeData-7SrPw{œdataTypeœ:œMergeDataœ,œidœ:œMergeData-7SrPwœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-UpdateData-DprRI{œfieldNameœ:œdataœ,œidœ:œUpdateData-DprRIœ,œinputTypesœ:null,œtypeœ:œDataœ}","className":""},{"source":"CustomComponent-Zdw7Q","sourceHandle":"{œdataTypeœ:œCustomTextIDœ,œidœ:œCustomComponent-Zdw7Qœ,œnameœ:œunique_idœ,œoutput_typesœ:[œTextœ]}","target":"UpdateData-DprRI","targetHandle":"{œfieldNameœ:œnew_dataœ,œidœ:œUpdateData-DprRIœ,œinputTypesœ:[œTextœ],œtypeœ:œdictœ}","data":{"targetHandle":{"fieldName":"new_data","id":"UpdateData-DprRI","inputTypes":["Text"],"type":"dict"},"sourceHandle":{"dataType":"CustomTextID","id":"CustomComponent-Zdw7Q","name":"unique_id","output_types":["Text"]}},"id":"reactflow__edge-CustomComponent-Zdw7Q{œdataTypeœ:œCustomTextIDœ,œidœ:œCustomComponent-Zdw7Qœ,œnameœ:œunique_idœ,œoutput_typesœ:[œTextœ]}-UpdateData-DprRI{œfieldNameœ:œnew_dataœ,œidœ:œUpdateData-DprRIœ,œinputTypesœ:[œTextœ],œtypeœ:œdictœ}","className":""},{"source":"ParseData-ByMh3","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-ByMh3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"CustomComponent-Zdw7Q","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-Zdw7Qœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"CustomComponent-Zdw7Q","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-ByMh3","name":"text","output_types":["Message"]}},"className":"","id":"reactflow__edge-ParseData-ByMh3{œdataTypeœ:œParseDataœ,œidœ:œParseData-ByMh3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-Zdw7Q{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-Zdw7Qœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"},{"source":"ParseData-ByMh3","sourceHandle":"{œdataTypeœ:œParseDataœ,œidœ:œParseData-ByMh3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"RetrievalQA-iIpv5","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œRetrievalQA-iIpv5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"RetrievalQA-iIpv5","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"ParseData","id":"ParseData-ByMh3","name":"text","output_types":["Message"]}},"className":"","id":"reactflow__edge-ParseData-ByMh3{œdataTypeœ:œParseDataœ,œidœ:œParseData-ByMh3œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-RetrievalQA-iIpv5{œfieldNameœ:œinput_valueœ,œidœ:œRetrievalQA-iIpv5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"},{"source":"RetrievalQA-iIpv5","sourceHandle":"{œdataTypeœ:œRetrievalQAœ,œidœ:œRetrievalQA-iIpv5œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}","target":"TextOutput-X4x75","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-X4x75œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-X4x75","inputTypes":["Message"],"type":"str"},"sourceHandle":{"dataType":"RetrievalQA","id":"RetrievalQA-iIpv5","name":"text","output_types":["Message"]}},"id":"reactflow__edge-RetrievalQA-iIpv5{œdataTypeœ:œRetrievalQAœ,œidœ:œRetrievalQA-iIpv5œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-TextOutput-X4x75{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-X4x75œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}","className":""},{"source":"CohereModel-p8Sdn","sourceHandle":"{œdataTypeœ:œCohereModelœ,œidœ:œCohereModel-p8Sdnœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}","target":"RetrievalQA-iIpv5","targetHandle":"{œfieldNameœ:œllmœ,œidœ:œRetrievalQA-iIpv5œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"llm","id":"RetrievalQA-iIpv5","inputTypes":["LanguageModel"],"type":"other"},"sourceHandle":{"dataType":"CohereModel","id":"CohereModel-p8Sdn","name":"model_output","output_types":["LanguageModel"]}},"id":"reactflow__edge-CohereModel-p8Sdn{œdataTypeœ:œCohereModelœ,œidœ:œCohereModel-p8Sdnœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-RetrievalQA-iIpv5{œfieldNameœ:œllmœ,œidœ:œRetrievalQA-iIpv5œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}","className":""},{"source":"OpenAIEmbeddings-Pvdwo","sourceHandle":"{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-Pvdwoœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}","target":"SupabaseVectorStore-7rVC0","targetHandle":"{œfieldNameœ:œembeddingœ,œidœ:œSupabaseVectorStore-7rVC0œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"embedding","id":"SupabaseVectorStore-7rVC0","inputTypes":["Embeddings"],"type":"other"},"sourceHandle":{"dataType":"OpenAIEmbeddings","id":"OpenAIEmbeddings-Pvdwo","name":"embeddings","output_types":["Embeddings"]}},"id":"reactflow__edge-OpenAIEmbeddings-Pvdwo{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-Pvdwoœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-SupabaseVectorStore-7rVC0{œfieldNameœ:œembeddingœ,œidœ:œSupabaseVectorStore-7rVC0œ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}","className":""},{"source":"UpdateData-DprRI","sourceHandle":"{œdataTypeœ:œUpdateDataœ,œidœ:œUpdateData-DprRIœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}","target":"SupabaseVectorStore-7rVC0","targetHandle":"{œfieldNameœ:œingest_dataœ,œidœ:œSupabaseVectorStore-7rVC0œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"ingest_data","id":"SupabaseVectorStore-7rVC0","inputTypes":["Data"],"type":"other"},"sourceHandle":{"dataType":"UpdateData","id":"UpdateData-DprRI","name":"data","output_types":["Data"]}},"id":"reactflow__edge-UpdateData-DprRI{œdataTypeœ:œUpdateDataœ,œidœ:œUpdateData-DprRIœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-SupabaseVectorStore-7rVC0{œfieldNameœ:œingest_dataœ,œidœ:œSupabaseVectorStore-7rVC0œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}","className":""},{"source":"SupabaseVectorStore-7rVC0","sourceHandle":"{œdataTypeœ:œSupabaseVectorStoreœ,œidœ:œSupabaseVectorStore-7rVC0œ,œnameœ:œbase_retrieverœ,œoutput_typesœ:[œRetrieverœ]}","target":"RetrievalQA-iIpv5","targetHandle":"{œfieldNameœ:œretrieverœ,œidœ:œRetrievalQA-iIpv5œ,œinputTypesœ:[œRetrieverœ],œtypeœ:œotherœ}","data":{"targetHandle":{"fieldName":"retriever","id":"RetrievalQA-iIpv5","inputTypes":["Retriever"],"type":"other"},"sourceHandle":{"dataType":"SupabaseVectorStore","id":"SupabaseVectorStore-7rVC0","name":"base_retriever","output_types":["Retriever"]}},"id":"reactflow__edge-SupabaseVectorStore-7rVC0{œdataTypeœ:œSupabaseVectorStoreœ,œidœ:œSupabaseVectorStore-7rVC0œ,œnameœ:œbase_retrieverœ,œoutput_typesœ:[œRetrieverœ]}-RetrievalQA-iIpv5{œfieldNameœ:œretrieverœ,œidœ:œRetrievalQA-iIpv5œ,œinputTypesœ:[œRetrieverœ],œtypeœ:œotherœ}","className":""}],"viewport":{"x":-1509.04058635393,"y":-647.4286410896352,"zoom":0.5000000000000059}},"description":"Visit https://docs.langflow.org/tutorials/rag-with-astradb for a detailed guide of this project.\nThis project give you both Ingestion and RAG in a single file. You'll need to visit https://astra.datastax.com/ to create an Astra DB instance, your Token and grab an API Endpoint.\nRunning this project requires you to add a file in the Files component, then define a Collection Name and click on the Play icon on the Astra DB component. \n\nAfter the ingestion ends you are ready to click on the Run button at the lower left corner and start asking questions about your data.","name":"UploadFlow","last_tested_version":"1.0.9","endpoint_name":null,"is_component":false}